{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 7 - Text generation with LSTM\n",
    "#\n",
    "# Step 1 (not assessed): build and train a model to generate text in the style of a corpus.\n",
    "#\n",
    "# Based on the Keras text generation example (https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py)\n",
    "#\n",
    "# Step 2: build a model to distinguish genuine from fake sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential modules\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Activation, Conv2D,Flatten, Dropout,LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import save_model\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to sample an index from an array of predictions.\n",
    "#\n",
    "# The input array 'preds' should be the output of a text generation model.\n",
    "# The elements contain the values of the units in the final layer.\n",
    "# Each unit corresponds to a character in the text alphabet.\n",
    "# The final layer should have SoftMax activation, and thus the\n",
    "# value corresponds to the 'strength of prediction' of that character\n",
    "# as the next output value---so the maximum value indicates which character\n",
    "# is most strongly predicted (considerd most likely) as the next one.\n",
    "#\n",
    "def sample(preds, temperature=1.0):\n",
    "    # Convert to high-precision datatype (we are going to be manipulating some\n",
    "    # very small values in this function)\n",
    "    preds = np.asarray(preds).astype('float64')  \n",
    "    \n",
    "    # The next line has the effect of raising each prediction value to the power 1/T.\n",
    "    # It's done using logs to improve numerical precision.  This is a kind of value-dependent\n",
    "    # scaling: for T < 1.0 (1/T > 1.0), small values are made smaller (proportionally) than \n",
    "    # large values (unlike a linear scaling, such as multiplication by 0.9, which scales all values\n",
    "    # the same).\n",
    "    #\n",
    "    # Example: Consider that we have only two symbols (letters) in our alphabet, and our \n",
    "    # probabilities are [0.2, 0.8].  A temperature of 1.0 means 'do not adjust the\n",
    "    # probabilities at all', so in this case there will be a 20% chance that the \n",
    "    # function will return 'symbol 0' and an 80% chance  that it will return 'symbol 1'.\n",
    "    # Note that symbol 1 is 4x more likely than symbol 0.\n",
    "    #\n",
    "    # Now: if we supply a temperature of 0.5, our probabilites will be raised to the\n",
    "    # power 1/0.5 = 2, becoming [0.04, 0.64].  These will then be normalized to sum to 1,\n",
    "    # but anyway it is clear that symbol 1 is here 16x (the square of 4x) more likely than \n",
    "    # symbol 0.\n",
    "    #\n",
    "    # Conversely, for a temperature of 2, our probabilities will be raised to 0.5 (square-rooted),\n",
    "    # becoming [.4472, 0.8944] - and so here symbol 1 is only 2x (sqrt of 4x) more likely than\n",
    "    # symbol 0.\n",
    "    #\n",
    "    # So: low temperatures make the distribution peakier, exaggerating the difference between\n",
    "    # values.  High temperatures flatten the distribution, reducing the difference between values.\n",
    "    #\n",
    "    # As the return value is a sample of the manipulated distribution, manipulating it to\n",
    "    # be peakier (by supplying a low temperature) makes the sample more conservative, i.e.\n",
    "    # more likely to pick the highest-probability symbol.\n",
    "    #\n",
    "    # Making the distribution flatter (by suppyling a high temperature) causes the\n",
    "    # sample to be less conservative, i.e. more likely to pick some lower-likelihood\n",
    "    # symbol.\n",
    "    #\n",
    "    # Phew!\n",
    "    preds = np.exp(np.log(preds) / temperature)\n",
    "    \n",
    "    preds = preds / np.sum(preds)  # ensure that probs sum to 1\n",
    "    probas = np.random.multinomial(1, preds, 1)  # take 1 sample from the distribution\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original corpus length: 600893\n",
      "length for training: 100000\n"
     ]
    }
   ],
   "source": [
    "# Decide how much data to use for training.\n",
    "# You might want to reduce this to ~100k for faster experimentation, and then bring it back\n",
    "# to 600k when you're happy with your network architecture.\n",
    "# IMPORTANT: make sure you end up with a 57-symbol alphabet after reducing the corpus size!\n",
    "# If the number of symbols (shown in the next cell) gets smaller than it was with the full\n",
    "# corpus, bring your sample size back up.  This is necessary because the encoding used for\n",
    "# training must match that used for assessment.\n",
    "desired_num_chars = 100*1000  # Max: 600893\n",
    "\n",
    "random.seed(43)  # Fix random seed for repeatable results.\n",
    "\n",
    "# Slurp down all of Nietzsche from Amazon.\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('original corpus length:', len(text))\n",
    "\n",
    "start_index = random.randint(0, len(text) - desired_num_chars - 1)\n",
    "text = text[start_index:start_index + desired_num_chars]\n",
    "text\n",
    "print('length for training:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ample, whether it be \"real\" or not, and why it keeps the outer\n",
      "world so resolutely at a distance, and other questions of the same\n",
      "description. the belief in \"immediate certainties\" is a moral naivete\n",
      "which does honour to us philosophers; but--we have now to cease being\n",
      "\"merely moral\" men! apart from morality, such belief is a folly which\n",
      "does little honour to us! if in middle-class life an ever-ready distrust\n",
      "is regarded as the sign of a \"bad character,\" and consequently as an\n",
      "imprudence, here among us, beyond the middle-class world and its yeas\n",
      "and nays, what should prevent our being imprudent and saying: the\n",
      "philosopher has at length a right to \"bad character,\" as the being who\n",
      "has hitherto been most befooled on earth--he is now under obligation\n",
      "to distrustfulness, to the wickedest squinting out of every abyss of\n",
      "suspicion.--forgive me the joke of this gloomy grimace and turn of\n",
      "expression; for i myself have long ago learned to think and estimate\n",
      "differently with regard to deceiving \n"
     ]
    }
   ],
   "source": [
    "# Let's have a quick look at a random exceprt.\n",
    "#\n",
    "# Caution: Nietzsche might drive you mad: dare you behold more than 1000 of his terrible chars..? \n",
    "sample_length = 1000\n",
    "\n",
    "random.seed(None)  # Seeds random from current time (so re-eval this cell for a new sample).\n",
    "\n",
    "start_index = random.randint(0, len(text) - sample_length - 1)\n",
    "print(text[start_index:start_index+sample_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 52\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# Establish the alphabet (set of symbols) we are going to use.\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "print(chars)\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))  # Map to look up index of a particular char (e.g. x['a'] = 0)\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))  # Map to look up char at an index (e.g. x[0] = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 33320\n"
     ]
    }
   ],
   "source": [
    "# Establish a training set of semi-redundant (i.e. overlapping) sequences of maxlen characters.\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []  # Not syntactic sentences, but just sequences of 40 chars pulled from the corpus.\n",
    "next_chars = [] # next_chars[n] stores the character which followed sentences[n]\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33320, 40, 52)\n",
      "(33320, 52)\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to one-hot encoding.\n",
    "# 'x' will contain the one-hot encoding of the training 'sentences'.\n",
    "# 'y' will contain the one-hot encoding of the 'next char' for each sentence.\n",
    "#\n",
    "# \n",
    "# Let's consider that we have N sentences of length L:\n",
    "#\n",
    "# The 'native' encoding is an NxL matrix where element [n][l]\n",
    "# is the symbol index for character at index (l) of sentence (n)\n",
    "# (e.g., say, 5, corresponding to 'e').\n",
    "#\n",
    "# The one-hot encoding is an NxLxS matrix, where S is the \n",
    "# number of symbols in the alphabet, such that element [n][l][s]\n",
    "# is 1 if the character at index (l) in sentence (n) has the\n",
    "# symbol index (s), and 0 otherwise.\n",
    "def onehot_encode(sentence, maxlen):\n",
    "    x = np.zeros((maxlen, len(chars)), dtype=np.bool)\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[t, char_indices[char]] = 1\n",
    "    return x\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    x[i,:,:] = onehot_encode(sentence, maxlen)\n",
    "    y[i, :] = onehot_encode(next_chars[i], 1)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the generator model: a single GRU layer with 128 cells.\n",
    "generator_model = Sequential()\n",
    "generator_model.add(GRU(128, input_shape=(maxlen, len(chars))))\n",
    "generator_model.add(Dense(len(chars)))\n",
    "generator_model.add(Activation('softmax'))\n",
    "\n",
    "# You could experiment with NAdam instead of RMSProp.\n",
    "optimizer = 'NAdam'\n",
    "generator_model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "trained_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_list(seed_list, length=400, temperature=0.25):\n",
    "    sentence_list = []\n",
    "    generated_list = []\n",
    "    n = len(seed_list)\n",
    "    # copy lists\n",
    "    for seed in seed_list:\n",
    "        sentence_list.append(seed[:])\n",
    "        generated_list.append(seed[:])    \n",
    "    \n",
    "    for i in range(length):\n",
    "      \n",
    "        workdone = (i+1)*1.0 / length\n",
    "        sys.stdout.write(\"\\rgenerating sentences: [{0:20s}] {1:.1f}%\".format('#' * int(workdone * 20), workdone*100))\n",
    "        sys.stdout.flush()\n",
    "            \n",
    "        x_pred_list = np.zeros((n, maxlen, len(chars)))\n",
    "        for j, sentence in enumerate(sentence_list):\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred_list[j, t, char_indices[char]] = 1.\n",
    "\n",
    "        start = time.time()\n",
    "        pred_list = generator_model.predict(x_pred_list, verbose=0)\n",
    "        end = time.time()\n",
    "\n",
    "        for j in range(n):\n",
    "            next_index = sample(pred_list[j,:], temperature)\n",
    "            next_char = indices_char[next_index]\n",
    "            generated_list[j] += next_char\n",
    "            sentence_list[j] = sentence_list[j][1:] + next_char\n",
    "    \n",
    "    sys.stdout.write(' - done\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    return generated_list\n",
    "\n",
    "def print_sentences(seeds, sentences):\n",
    "    for seed, sentence in zip(seeds, sentences):\n",
    "        print('-'*5)\n",
    "        sys.stdout.write('\\x1b[32m')\n",
    "        sys.stdout.write(sentence[0:len(seed)])\n",
    "        sys.stdout.write('\\x1b[34m')\n",
    "        sys.stdout.write(sentence[len(seed):-1])\n",
    "        sys.stdout.write('\\x1b[m')\n",
    "        sys.stdout.write('\\n')    \n",
    "        sys.stdout.flush()\n",
    "        \n",
    "def pick_sentences(n, maxlen):\n",
    "    global text    \n",
    "    start_index_list = np.random.randint(len(text) - maxlen - 1, size=(1, n)).flatten().tolist()\n",
    "    seed_list = [] \n",
    "    for start_index in start_index_list:\n",
    "        seed_list.append(text[start_index: start_index + maxlen])\n",
    "    return seed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/4\n",
      "33320/33320 [==============================] - 6s 188us/step - loss: 3.2121\n",
      "Epoch 2/4\n",
      "33320/33320 [==============================] - 3s 100us/step - loss: 2.8703\n",
      "Epoch 3/4\n",
      "33320/33320 [==============================] - 3s 101us/step - loss: 2.6480\n",
      "Epoch 4/4\n",
      "33320/33320 [==============================] - 3s 101us/step - loss: 2.4867\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32m these wrongly\n",
      "named \"free spirits\"--as \u001b[34mand on the an the the the the and an the the the the the the the the it and ine so the the tithe the the the the the the son the and the sin the the to the the the the the the the the in the the and and the ind the the the the in the the an on the the and and in and an ind the the the the the the the the an ind in the sous an the the on the in the the the the se and the the and the and sous and a\u001b[m\n",
      "-----\n",
      "\u001b[32me dry, fine air of florence, and cannot\n",
      "\u001b[34mand the the sore the the the the the the the the the the the the the the the the the to the se the the the ind of whe the the and the se on the the in in the the the the the the the ind and an the the the the the the the in the the the an an and and an the the in en and of an ens an the the the the ind and the the the the the the the ind an in the the the the the the the the the the the the the t\u001b[m\n",
      "-----\n",
      "\u001b[32me of perpetual readiness for the\n",
      "\"coming\u001b[34m and and an the the the the sore an the the the an the the the the the the the the the sere the the the the the the thin the the the and and the the the the and an an the the the the the the the the the more the the the pere the the the in the the the the the the the the the the the the and an the ond the the tore and and the se the the the tale in an the the on the the the and and in the the and\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/4\n",
      "33320/33320 [==============================] - 3s 102us/step - loss: 2.3873\n",
      "Epoch 2/4\n",
      "33320/33320 [==============================] - 3s 99us/step - loss: 2.3150\n",
      "Epoch 3/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 2.2590\n",
      "Epoch 4/4\n",
      "33320/33320 [==============================] - 3s 99us/step - loss: 2.2073\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32m these wrongly\n",
      "named \"free spirits\"--as \u001b[34mand the seveling and the the the hal the ertere the his the and the has the and and resing the sere the and and the the mont and the sore the mathe the han the the seand the sont and has the her and at in the sere the the seand the the sopere the that the seat of the the sere the mant on the inte the intily of the the the mant of the hat all the and and the and the in the and the the sere the thi\u001b[m\n",
      "-----\n",
      "\u001b[32me dry, fine air of florence, and cannot\n",
      "\u001b[34mthe the sont and and at on the the wing and and the the mone the mont and the here the and the soment of the and the sere the and on the hals and and the sall of the ment and and the hat and the the that and and the mon the and the sore the thith in the her and and and and the seand the corse the and and the the sore the the sente the her and and and the seand the hal  and the the sestion the the\u001b[m\n",
      "-----\n",
      "\u001b[32me of perpetual readiness for the\n",
      "\"coming\u001b[34m and worle the and and and the hich on the wion the hat and and the will on the ore the the the with the hat and the mone the ats of the here the hat on the the sould the and of the the serene the here the here the inte the and and the the and that of the sont of the and the hor the mand the inte the the soust and the the wire and and the sent and and the har the the mont of the hal the sore the \u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/4\n",
      "33320/33320 [==============================] - 3s 97us/step - loss: 2.1600\n",
      "Epoch 2/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 2.1163\n",
      "Epoch 3/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 2.0753\n",
      "Epoch 4/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 2.0334\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32m these wrongly\n",
      "named \"free spirits\"--as \u001b[34mthe conting the seand the seant the seat of the some to the ingertion of the suct of the sound to the ther the will and in the seand the some that the sere the contion and the sould the sope to the ingere the mant the sere that has the sout the sople stonct of the sore the sout be and the sime and and mone some the sope the sound songer and and the suct the sould the sould the sing the sent of th\u001b[m\n",
      "-----\n",
      "\u001b[32me dry, fine air of florence, and cannot\n",
      "\u001b[34mand of the such the sore the sofed the prece and and and in the sere the soming the such the sere the sould the sould and the sound the sean and the seand the sich the sout the sont the seand the sace the sonte the sont and contice porte in the seand the some te the sont the sing the seat of the sance and the sound to the sould the seat of the seat of the soment of the ingertion of the sould the \u001b[m\n",
      "-----\n",
      "\u001b[32me of perpetual readiness for the\n",
      "\"coming\u001b[34m of the sont and conting the suct of the sould the sure the sould the sould the such the contice and in the sinct of the will the sice the mant the mant and the will the ment the sould the sould and as is the sonte the seat of the ponting the stould the seand the such the thit se the seand the sone the sont the senting the sout the seand the mant of the sont the seand the sere the seand and the s\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/4\n",
      "33320/33320 [==============================] - 3s 100us/step - loss: 1.9917\n",
      "Epoch 2/4\n",
      "33320/33320 [==============================] - 3s 99us/step - loss: 1.9528\n",
      "Epoch 3/4\n",
      "33320/33320 [==============================] - 3s 97us/step - loss: 1.9160\n",
      "Epoch 4/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.8834\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32m these wrongly\n",
      "named \"free spirits\"--as \u001b[34mthe soul has of the mant the senter the could the soul the sond the sould the all the sand the with there is the searing the seat of the sone and solling the mand the suptering the dinger, the mont of the sould the suchation and the sould the some all the sone the sonter the mant of the sould the mand the plose the mant reance of the sonte the sander of the mant of the promation and the with the \u001b[m\n",
      "-----\n",
      "\u001b[32me dry, fine air of florence, and cannot\n",
      "\u001b[34mon the seart and the sucher and the seally and the sence of the sore the mand and the mant the promently and the conter and the sould the proment of the wall the mant the will the sain the sone the stions of the will the mant to the stion and the still the wall the mand the sint of the sounden and the sore the sentersting the such the seand the mant of the santer the sore the manithing and the ma\u001b[m\n",
      "-----\n",
      "\u001b[32me of perpetual readiness for the\n",
      "\"coming\u001b[34m the mant in the promation of the mont the promone at in the will the mant the senter and the some all the mand the mant the continition and the senter the prouth the suching the mant the mant the probeding the sears and manker and the cander the stion of the sould the sore the saction of the sore the contering the mant the mand the sould to the sereant the mand the sears the sore the sould the s\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.8492\n",
      "Epoch 2/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.8170\n",
      "Epoch 3/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.7831\n",
      "Epoch 4/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.7549\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32m these wrongly\n",
      "named \"free spirits\"--as \u001b[34mthe corts the sould the will there it there in the sone beans there ald serman there it there ard its longerse the sain the sere there and which the more thing the more to the suct of the sore to be of the sonte for the soul and there is the conterstion, and more sould the with there is the saint to the prones the conterstont to the sould there is the seart to the sore the sore there in the conte\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\u001b[32me dry, fine air of florence, and cannot\n",
      "\u001b[34mand sonether there is the conterstont of the soul has has there is the sore as the sereat of the sore then and the mand the sore betion and the sereation of the corting to the whilh the soul the soul there in the sonting there is the mant would to the sere for the sore to the wall there is the sente in the conterstored the sore there is the sente the conte the sore the sonething the still there i\u001b[m\n",
      "-----\n",
      "\u001b[32me of perpetual readiness for the\n",
      "\"coming\u001b[34m the sore then is the sonether and the sore the sore there ard the sore as the sould there is the mant of the sonething the saint the mant reans the soul has there in the sonether to chell the sould the conterstonts and the cort of the sonte the sore there it seance sermat there is the soul which is the sere then the sance of the sore then and there it is the sonture the soul the sente of the son\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/4\n",
      "33320/33320 [==============================] - 3s 103us/step - loss: 1.7258\n",
      "Epoch 2/4\n",
      "33320/33320 [==============================] - 3s 99us/step - loss: 1.6961\n",
      "Epoch 3/4\n",
      "33320/33320 [==============================] - 3s 97us/step - loss: 1.6656\n",
      "Epoch 4/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.6377\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32m these wrongly\n",
      "named \"free spirits\"--as \u001b[34mthe soul and the wart of the sore for itself in the soul and the prose of the soul and to the most the sore of the some ass and disture of the sore then and has has there is the sains to the such as the sense of the sense of the some to has there is the sears of the contures of the sore there ar ald solition of the sains the could there is the sears to the sense of the soul of the conturest to th\u001b[m\n",
      "-----\n",
      "\u001b[32me dry, fine air of florence, and cannot\n",
      "\u001b[34mof the soul there it is the seart of the conture of the contrerity, and sore is the sense of the soit, the contreritions of the soul of a surder the cortle of the sonething in the corts the cortually and to the faines and suppesion of the cort and such as the sere fanterined the will to the sense of the sense of the contuines of the sense of the soness of the most the sist of the contrarion of th\u001b[m\n",
      "-----\n",
      "\u001b[32me of perpetual readiness for the\n",
      "\"coming\u001b[34m of the sone seans to the sone sone promen some posting, and even the most the serman the could to the reals to the sours for the soil and the soul there is the soul the could to as the sained and even the soul holly on the sente of the sone sone sears belies of the sore for the soul and the contually and even the sonte of the sone sears to the sours lose as the sears for which the prose ous the \u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.6080\n",
      "Epoch 2/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.5801\n",
      "Epoch 3/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.5500\n",
      "Epoch 4/4\n",
      "33320/33320 [==============================] - 3s 97us/step - loss: 1.5199\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32m these wrongly\n",
      "named \"free spirits\"--as \u001b[34mthe mast of the soul and the most of its of the sonething and refines of the sore, the still the corts the probestly which is it secraticnally, and supe fintlound the still something be ofter of the soul and refiness and refiness and that it is the still something of the contervan inderstoon and refanticill endicinel something philosopher, and conception of the soul and something of the sainted a\u001b[m\n",
      "-----\n",
      "\u001b[32me dry, fine air of florence, and cannot\n",
      "\u001b[34man and to suppece, the mast of the sace finglentle still to philosopher the desigite the real and the soulthing of the soul of the soul and refiness of the contrince the prosenops into the soul and the still the still and the spict and which the prowe our the still the still to still sonethed to chully, and the still something of the soul and the still something promen portents betion of the soul\u001b[m\n",
      "-----\n",
      "\u001b[32me of perpetual readiness for the\n",
      "\"coming\u001b[34m of the soul and more sight the still the could not of man will to the will to the something of the soul and the still so mat in the soul and the still to stime and the still to leneres that the sace fan and the still to the sanes to action and which the preserved to the sore of the sonet of the sout, the still the preation of the soul and this sould for the still something of the soul and sace o\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/4\n",
      "33320/33320 [==============================] - 3s 101us/step - loss: 1.4880\n",
      "Epoch 2/4\n",
      "33320/33320 [==============================] - 3s 99us/step - loss: 1.4614\n",
      "Epoch 3/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.4304\n",
      "Epoch 4/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.4027\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32m these wrongly\n",
      "named \"free spirits\"--as \u001b[34mto such and such a the coutsernter of the sonitions of the sonitions and decige of the sonitions and self-stipe of the sontimions of the sonticions and conscient \"free of the soul and even the sontimions out net action of precession of manthist and sentasing some postice to the sonticily and disture or sich a the most a the contrort, and some peas hought of the most of its of the sonitions and re\u001b[m\n",
      "-----\n",
      "\u001b[32me dry, fine air of florence, and cannot\n",
      "\u001b[34mof themselves of the sonicion, and sentesion of still something of the soun, and such a the contrart and all to disture the still soll presionally of the soul, there it is a most succalies in the sentestion of the sonticions, the ereation of the soun and suld stions of the sacred to his into the still something of the saint in the conturulate consciend enthersion of manter the still something of \u001b[m\n",
      "-----\n",
      "\u001b[32me of perpetual readiness for the\n",
      "\"coming\u001b[34m of still something of the soul, to have serman something of theis falsenter, and also the senses and self-stion of themselves of the soner of themse veller of the soul and even the spicite and alse the option of themselves of the sonitions of the sonicion of the sone conts the sentesion of the sour to the soul and into the senses and deniger end sensigion of the sanical of atromation and more fi\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.3718\n",
      "Epoch 2/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.3421\n",
      "Epoch 3/4\n",
      "33320/33320 [==============================] - 3s 97us/step - loss: 1.3085\n",
      "Epoch 4/4\n",
      "33320/33320 [==============================] - 3s 98us/step - loss: 1.2773\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32m these wrongly\n",
      "named \"free spirits\"--as \u001b[34mthe rear to the some pessing the rean a surder for the mast regards the still something--it is and hisself to themse vere of the sontimions of the opesation and religions and precossing the experion for at ind condsichat condection of the condetions of the interpretion of the sour to the wolld is an and to ach ag the intophing of a manks of a most verinater, as reades the rean a gromatical of sen\u001b[m\n",
      "-----\n",
      "\u001b[32me dry, fine air of florence, and cannot\n",
      "\u001b[34mof the soul and how into the \"past the everaty and even philosopher, whe who what which they and refiness and denich of the soul and therefiens and derenity and the most self-metration of the sonet of the sore of himself still something--for the spice and the spiret of the inceprer of selves, and is the most self--the of at the sensen and all the speal, the wrich and is not one concequan somethin\u001b[m\n",
      "-----\n",
      "\u001b[32me of perpetual readiness for the\n",
      "\"coming\u001b[34m as a liet of the inceppesion of the sour, and surd for the most religion of the most self-metrese of the spice of the sonting to have a the rean a phelostin the most is is not one man was therefion of the sone fantion of the sonet of the spice of the sonting, in a mas being so mas the mather to cass of gore, and werre he worlery on the sand to all our the soul the reans the most succoud, and the\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Generate 3 seeds which we will use to inspect the progress of our training:\n",
    "preview_seeds = pick_sentences(3, maxlen=40)\n",
    "\n",
    "# Train the model, output generated text after each iteration\n",
    "for iteration in range(1, 10):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    generator_model.fit(x, y,\n",
    "                  batch_size=1024,\n",
    "                  epochs=4)\n",
    "\n",
    "    generated_sentences = generate_sentence_list(preview_seeds)\n",
    "    print_sentences(preview_seeds, generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mc processes (naturally also,\n",
      "refines and\u001b[34m refine of this hand sean and therefion\u001b[m\n",
      "-----\n",
      "\u001b[32me la souffrance humaine\"; that is its\n",
      "\"g\u001b[34mions of the mate as a lition of the son\u001b[m\n",
      "-----\n",
      "\u001b[32mould prevent our being imprudent and say\u001b[34m, the way the reand therefiens of the s\u001b[m\n",
      "-----\n",
      "\u001b[32m thoughtlessness, imprudence, heartiness\u001b[34m of the sande it means of a live of the\u001b[m\n",
      "-----\n",
      "\u001b[32ms, and prefers to try\n",
      "conclusions with t\u001b[34mhe suppese of thim things of the soneth\u001b[m\n",
      "-----\n",
      "\u001b[32m good man. the\n",
      "hitherto existing psychol\u001b[34mogy has to censine the sand that the se\u001b[m\n",
      "-----\n",
      "\u001b[32m the exception!\" and he would go down, a\u001b[34mnd its porsens the most self--the most \u001b[m\n",
      "-----\n",
      "\u001b[32mike before witnesses--sometimes they\n",
      "wal\u001b[34mthe with a gerean there is and refine a\u001b[m\n",
      "-----\n",
      "\u001b[32megories; with it in his hand he said: \"t\u001b[34mhe condetion of the sone as a mas firmu\u001b[m\n",
      "-----\n",
      "\u001b[32mow bad,\n",
      "does every long war make one, wh\u001b[34mich to sempentes of a matill end all of\u001b[m\n",
      "-----\n",
      "\u001b[32mer good when one's neighbour\n",
      "takes it in\u001b[34mtuplesions of the interpretion of the s\u001b[m\n",
      "-----\n",
      "\u001b[32mickedness and haughtiness is\n",
      "immediately\u001b[34m, and sermand the spore of the sones an\u001b[m\n",
      "-----\n",
      "\u001b[32m, destined and trained to command, in wh\u001b[34mich the one as it soul, desires the spi\u001b[m\n",
      "-----\n",
      "\u001b[32mred\n",
      "from its consequences; the action in\u001b[34m the canes the still something of a man\u001b[m\n",
      "-----\n",
      "\u001b[32me origin, if by virtue of superior\n",
      "spiri\u001b[34mture of a manks of a mast regards think\u001b[m\n",
      "-----\n",
      "\u001b[32mts--namely, a sort of revolt\n",
      "against the\u001b[34m eved to at and more so cart of the int\u001b[m\n",
      "-----\n",
      "\u001b[32mt etre sec,\n",
      "clair, sans illusion. un ban\u001b[34m and all ore is the opesation and refin\u001b[m\n",
      "-----\n",
      "\u001b[32mre are\n",
      "men, things, and sayings on such \u001b[34ma stall it most the which is becked wit\u001b[m\n",
      "-----\n",
      "\u001b[32my one name. inasmuch as\n",
      "in the given cir\u001b[34mture to as the indigite philosophired a\u001b[m\n",
      "-----\n",
      "\u001b[32me--circulus vitiosus deus?\n",
      "\n",
      "57. the dist\u001b[34mans as something of the soul, geans for\u001b[m\n",
      "-----\n",
      "\u001b[32m think and live otherwise--namely, kurma\u001b[34mdice poreen the express of a mast relig\u001b[m\n",
      "-----\n",
      "\u001b[32mrely free spirits, but something more, h\u001b[34mender of the sonething interpretion of \u001b[m\n",
      "-----\n",
      "\u001b[32mermitted to be a little ironical towards\u001b[34msical theresion of the sonet of the int\u001b[m\n",
      "-----\n",
      "\u001b[32mtill lead a\n",
      "dangerous after-life in plac\u001b[34me of the soul will not deering the prob\u001b[m\n",
      "-----\n",
      "\u001b[32merent, which does not wish to be misunde\u001b[34mrstonce the everation of the soul the r\u001b[m\n",
      "-----\n",
      "\u001b[32m and when we interpret and intermix this\u001b[34m fanditions of the interpretion of the \u001b[m\n",
      "-----\n",
      "\u001b[32mous life (alike for its\n",
      "favourite micros\u001b[34m of the interpretion of the soul redong\u001b[m\n",
      "-----\n",
      "\u001b[32md to a\n",
      "tender, many-sided, and very fast\u001b[34mical of and religion of the most subjec\u001b[m\n",
      "-----\n",
      "\u001b[32ment history of an action:\n",
      "under the infl\u001b[34miences, and sure of the sonething there\u001b[m\n",
      "-----\n",
      "\u001b[32mn accompanying muscular\n",
      "sensation, which\u001b[34m to sempentes the eved to as a mas pros\u001b[m\n",
      "-----\n",
      "\u001b[32mlso, is what you want; and\n",
      "therefore \"ch\u001b[34meere, and herd perhaps all the which he\u001b[m\n",
      "-----\n",
      "\u001b[32mfiguration and embellishment, something \u001b[34mof the interpretion of the soul readion\u001b[m\n",
      "-----\n",
      "\u001b[32mto present--long, heavy, difficult, dang\u001b[34me of the sonem, and alfouth and all the\u001b[m\n",
      "-----\n",
      "\u001b[32mt-minded toleration, on the roman \"catho\u001b[34mur, and the most succless of the spirit\u001b[m\n",
      "-----\n",
      "\u001b[32mife!\n",
      "\n",
      "25. after such a cheerful commence\u001b[34md to sense of this sact, the proden--an\u001b[m\n",
      "-----\n",
      "\u001b[32m degrees\n",
      "and many refinements of gradati\u001b[34mon of the manks of its of its liffering\u001b[m\n",
      "-----\n",
      "\u001b[32m really youthfulness,\n",
      "notwithstanding th\u001b[34me mas houded to the most is is not and \u001b[m\n",
      "-----\n",
      "\u001b[32my,\n",
      "with something of transfiguration and\u001b[34m requires and ever the still something \u001b[m\n",
      "-----\n",
      "\u001b[32me a greater likelihood of success; not t\u001b[34mhe contrired enctusions and dening the \u001b[m\n",
      "-----\n",
      "\u001b[32m and this by means of pale, cold, grey c\u001b[34monstion?\"--the requirest portently the \u001b[m\n",
      "-----\n",
      "\u001b[32ms, for instance, understood\n",
      "this fact. w\u001b[34mhere the prodencl, and the most surder,\u001b[m\n",
      "-----\n",
      "\u001b[32m to\n",
      "which he is compelled by his modern \u001b[34mprocess of the sones of the indection o\u001b[m\n",
      "-----\n",
      "\u001b[32mour of the\n",
      "genuine, tender, stupid beads\u001b[34ming for have they are all art seli-itio\u001b[m\n",
      "-----\n",
      "\u001b[32mght to the noble idlers, the virtuous,\n",
      "t\u001b[34mhe incepred the opeater, and as the mos\u001b[m\n",
      "-----\n",
      "\u001b[32mskin--which, like every skin, betrays so\u001b[34mre for the still something of the conce\u001b[m\n",
      "-----\n",
      "\u001b[32meptions?\"--that\n",
      "they please--him who has\u001b[34m hearther the prosenols all of the soul\u001b[m\n",
      "-----\n",
      "\u001b[32mestion how and where the plant \"man\" has\u001b[34m head to his houded to themse vere of t\u001b[m\n",
      "-----\n",
      "\u001b[32micial, especially in their\n",
      "innate partia\u001b[34mnal straticl to senses and derenity the\u001b[m\n",
      "-----\n",
      "\u001b[32m that almost\n",
      "every word, and the word \"t\u001b[34mo lave a the read to sense of the spire\u001b[m\n",
      "-----\n",
      "\u001b[32mhimself. kant was first and foremost pro\u001b[34msoun ond and sentame reanice the still \u001b[m\n",
      "-----\n",
      "\u001b[32mght in\n",
      "self-control are on the increase.\u001b[34m the most surden and refine and therefi\u001b[m\n",
      "-----\n",
      "\u001b[32m emotions, in\n",
      "which everything still lie\u001b[34mg the will to penserve time the still s\u001b[m\n",
      "-----\n",
      "\u001b[32mbethink themselves before putting down t\u001b[34mhat the still something of the one all \u001b[m\n",
      "-----\n",
      "\u001b[32m mantles of light, appropriators, althou\u001b[34mgh they are all ore is the soul relogid\u001b[m\n",
      "-----\n",
      "\u001b[32m and play; and not only the play, but ac\u001b[34mt in the sand, in the sonething instire\u001b[m\n",
      "-----\n",
      "\u001b[32mosophy, that of schopenhauer, we find al\u001b[34mdong-and as it more to be it mas the re\u001b[m\n",
      "-----\n",
      "\u001b[32m guidance of similar grammatical\n",
      "functio\u001b[34mns has the mast religion as the still s\u001b[m\n",
      "-----\n",
      "\u001b[32mone has\n",
      "got eyes for beholding this marv\u001b[34melly in the saired to the world he deve\u001b[m\n",
      "-----\n",
      "\u001b[32mtable time of it; eventually, however, h\u001b[34me denere or the sonethat of centain the\u001b[m\n",
      "-----\n",
      "\u001b[32mly and\n",
      "frightfully with this very folly.\u001b[34m the everation of the soul the rean a g\u001b[m\n",
      "-----\n",
      "\u001b[32m an action:\n",
      "under the influence of this \u001b[34mhand sere posticions and desing, and th\u001b[m\n",
      "-----\n",
      "\u001b[32m-going people, there is seldom any idea \u001b[34mthat the still something of the of ence\u001b[m\n",
      "-----\n",
      "\u001b[32mase? what? \"miracle\" only an error of\n",
      "in\u001b[34md ear has the mas the say to devert whi\u001b[m\n",
      "-----\n",
      "\u001b[32m nor better than we\": a fine instance of\u001b[34m the some perte be no and even the most\u001b[m\n",
      "-----\n",
      "\u001b[32mnowhere is it\n",
      "more obligatory to put asi\u001b[34mses and refire a matn and there is and \u001b[m\n",
      "-----\n",
      "\u001b[32m is certainly not the least charm of a t\u001b[34mhat the spire of the still something of\u001b[m\n",
      "-----\n",
      "\u001b[32m variety among germans--pardon\n",
      "me for st\u001b[34mheng and even the mast the spidiog to a\u001b[m\n",
      "-----\n",
      "\u001b[32mo ad absurdum, if the conception causa s\u001b[34men ate cann a shers perhaps the inderen\u001b[m\n",
      "-----\n",
      "\u001b[32m\n",
      "to vent its passion upon them: youth in\u001b[34m the gained dignter, and all the sone a\u001b[m\n",
      "-----\n",
      "\u001b[32mthe prose of lessing, imitate the tempo \u001b[34mappread to sense of the sone allay and \u001b[m\n",
      "-----\n",
      "\u001b[32mr\"--it would simply be \"will to power,\" \u001b[34ma mas the sentesion of the soul reare o\u001b[m\n",
      "-----\n",
      "\u001b[32me\n",
      "differently with regard to deceiving a\u001b[34mnd the prosend the everation of the son\u001b[m\n",
      "-----\n",
      "\u001b[32mer developed if life is to be further\n",
      "de\u001b[34mssimed conscient (was the prodence to t\u001b[m\n",
      "-----\n",
      "\u001b[32m in the religious life of the ancient\n",
      "gr\u001b[34mamsto is not to the would dears of the \u001b[m\n",
      "-----\n",
      "\u001b[32mmost ashamed: there is not only deceit b\u001b[34meer an and in the condettance, and the \u001b[m\n",
      "-----\n",
      "\u001b[32m special case, the philosopher thus find\u001b[34ms for the spire of the still something \u001b[m\n",
      "-----\n",
      "\u001b[32mthe philosopher, as we free spirits unde\u001b[34mrstoon for the will there is and henous\u001b[m\n",
      "-----\n",
      "\u001b[32mmay run, hidden\n",
      "ones under the mantles o\u001b[34mf such and every hand of all agreares a\u001b[m\n",
      "-----\n",
      "\u001b[32m the exception; and in view of the fact \u001b[34mto the world he wart shirng the were of\u001b[m\n",
      "-----\n",
      "\u001b[32mhe best\n",
      "right, but without being obliged\u001b[34m, and as the mast of the prodence to an\u001b[m\n",
      "-----\n",
      "\u001b[32mts destructive effect on the higher orde\u001b[34mr thin shire perhaps all the shill of a\u001b[m\n",
      "-----\n",
      "\u001b[32msion contradicts itself; that which can \u001b[34msempestancl of the soul, all our to des\u001b[m\n",
      "-----\n",
      "\u001b[32md also the most wicked consciences of to\u001b[34m such a greest out as there is and of t\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\u001b[32m to say that the subject \"i\" is the cond\u001b[34metion of the soul reare of the still so\u001b[m\n",
      "-----\n",
      "\u001b[32murthest extent (to absurdity, if i may b\u001b[34me allom the ond mist and is the sandini\u001b[m\n",
      "-----\n",
      "\u001b[32m, our thoughts a godlike\n",
      "desire for want\u001b[34m are sonitions to their gromon a reario\u001b[m\n",
      "-----\n",
      "\u001b[32m doctrine of the relations\n",
      "of supremacy \u001b[34mprose ould conscare for the most religi\u001b[m\n",
      "-----\n",
      "\u001b[32mre deeply attached to their\n",
      "catholicism \u001b[34mand vertur the still something of a man\u001b[m\n",
      "-----\n",
      "\u001b[32mace of the \"immediate certainty\" in whic\u001b[34mh the pholosopher, which the existive a\u001b[m\n",
      "-----\n",
      "\u001b[32mto the perspective view\n",
      "of life. and fin\u001b[34mdlees than the stire of the sontimions \u001b[m\n",
      "-----\n",
      "\u001b[32mo get out of\n",
      "the business, no matter how\u001b[34m ond and man fould the spirit of the in\u001b[m\n",
      "-----\n",
      "\u001b[32mch a desire to be clear what spectacle o\u001b[34mf the still something of the sonet of t\u001b[m\n",
      "-----\n",
      "\u001b[32mand thereby\n",
      "to retain their satisfaction\u001b[34m of the sonet of the most surders and d\u001b[m\n",
      "-----\n",
      "\u001b[32mit, his eyes will some day be\n",
      "opened to \u001b[34mbe allot of the condet and perhaps all \u001b[m\n",
      "-----\n",
      "\u001b[32mto which mankind has attained. that love\u001b[34ms and refire a pay the mather the sone \u001b[m\n",
      "-----\n",
      "\u001b[32mas found no\n",
      "\"bible,\" nor anything egypti\u001b[34mse ffees songit of a letill end and sor\u001b[m\n",
      "-----\n",
      "\u001b[32mers.\" this name itself is after all only\u001b[34m as not the spice of the sontiments man\u001b[m\n",
      "-----\n",
      "\u001b[32monly understand this \"could be\"! he was \u001b[34mtherevilation of the soul the reans the\u001b[m\n",
      "-----\n",
      "\u001b[32meads, and they still\n",
      "rub them today. peo\u001b[34mple of the sonethen there is and tore a\u001b[m\n",
      "-----\n",
      "\u001b[32mnity, which afterwards\n",
      "branches off and \u001b[34mdeneres the still so mare the most is t\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# For a more complete inspection, print out a load of sentences:\n",
    "#\n",
    "num_sentences = 100             # how many to generate\n",
    "sentence_length = 40            # 100--400 is good\n",
    "sample_temperature = 0.25       # see discussion of temperature up near the top\n",
    "\n",
    "start_index_list = np.random.randint(len(text) - maxlen - 1, size=(1, num_sentences)).flatten().tolist()\n",
    "preview_seeds = [] \n",
    "for start_index in start_index_list:\n",
    "    preview_seeds.append(text[start_index: start_index + maxlen])\n",
    "\n",
    "generated_sentences = generate_sentence_list(preview_seeds, length=sentence_length, temperature=sample_temperature) \n",
    "print_sentences(preview_seeds, generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a checkpoint, which will let you download and re-upload (or add to git) this model.\n",
    "save_model(generator_model, './generator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sentences: [#####               ] 27.5%"
     ]
    }
   ],
   "source": [
    "# Generating the training fake sentences for the Discriminator network\n",
    "#\n",
    "# These are saved to the file 'fake.pkl' -- you could download this to your\n",
    "# user drive and re-upload it in a subsequent session, to save regenerating\n",
    "# it again (in which case you don't need to evaluate this cell).\n",
    "\n",
    "training_seeds = pick_sentences(3000, maxlen=40)\n",
    "training_generated_sentences = generate_sentence_list(training_seeds, length=40)\n",
    "# Strip out the initial 40 chars (the seed sequence, which is genuine data from the corpus).\n",
    "for i, sentence in enumerate(training_generated_sentences):\n",
    "    training_generated_sentences[i] = sentence[40:40+40]\n",
    "    \n",
    "output = open('fake.pkl', 'wb')\n",
    "pickle.dump(training_seeds, output)\n",
    "pickle.dump(training_generated_sentences, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set from the file\n",
    "pkl_file = open('fake.pkl', 'rb')\n",
    "training_seeds = pickle.load(pkl_file)\n",
    "training_generated_sentences = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a 50:50 set of 'fake' (generated) and genuine sentences:\n",
    "num_generated = len(training_generated_sentences)\n",
    "training_real_sentences = pick_sentences(num_generated, maxlen=40)\n",
    "\n",
    "all_training_sentences = training_generated_sentences + training_real_sentences\n",
    "n = len(all_training_sentences)\n",
    "x = np.zeros((n, 40, len(chars)))\n",
    "y = np.zeros((n, 1))\n",
    "\n",
    "for i, sentence in enumerate(all_training_sentences):\n",
    "    x[i, :, :] = onehot_encode(sentence, maxlen=40)\n",
    "y[num_generated:] = 1  # Encodes the fact that sentences with indexes larger than (num_generated) are real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "\n",
    "# Define some layers here..\n",
    "\n",
    "discriminator_model = Sequential()\n",
    "discriminator_model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "\n",
    "\n",
    "\n",
    "discriminator_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use your layers to create the model.\n",
    "\n",
    "opt = 'NAdam'\n",
    "# Setup the optimisation strategy.\n",
    "discriminator_model.compile(optimizer=opt,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "                             \n",
    "print('compiled.')\n",
    "discriminator_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[x_train, x_test, y_train, y_test] = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "discriminator_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=1024) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you're happy with your discriminator model, evaluate this cell to save it:\n",
    "save_model(discriminator_model, './discriminator_model.h5')\n",
    "# Run these commands in the terminal to submit your model for assessment.\n",
    "# git add lab-07/discriminator_model.h5\n",
    "# git commit -m \"Add/update discriminator model.\"\n",
    "# git push\n",
    "# submit-lab 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
